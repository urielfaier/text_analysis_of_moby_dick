---
title: "R Text Analysis for Moby Dick"
author: "Uriel Faier"
output: html_notebook
---

```{r, include=FALSE}
library(tidyverse) # This includes dplyr, stringr, ggplot2, .. 
library(data.table)
library(ggthemes)
library(stringr)
library(tidytext) 
library(rvest)
```


## Introduction

Welcome to the Moby Dick Text Analysis project! In this project, we embark on a journey through the pages of Herman Melville's timeless classic, Moby Dick, using the R programming language for comprehensive textual analysis.

### Project Objectives:

Our main objective is to uncover the intricacies of Moby Dick's text through a series of analytical tasks:

1. **Data Acquisition:** We'll begin by extracting the complete text of Moby Dick from the Gutenberg project and preparing it for analysis.

2. **Word Frequency Analysis:** Next, we'll delve into the distribution of word lengths, compute word frequencies, and identify the most common words in the text.

3. **Chapter Structure Examination:** We'll analyze the chapter structure of Moby Dick, including word counts per chapter, and identify significant patterns or themes.


---


### Data Acquisition:

Before we begin our analysis, we need to acquire the text of Moby Dick from the Gutenberg project. We'll use the `rvest` package in R to read the HTML content of the book's webpage and extract the text.

```{r}
## Load necessary libraries
library(rvest)

## Define the URL for Moby Dick on Gutenberg
url <- "https://www.gutenberg.org/files/2701/2701-h/2701-h.htm"

## Read the HTML content of the webpage
md_html <- read_html(url)

## Extract the text of the book from the HTML content
md <- html_text(html_nodes(md_html, "body"))

## Extract the title of the book
title <- html_text(html_nodes(md_html, "title"))
```


### Word Frequency Analysis:

Now that we have the text of Moby Dick, let's analyze the distribution of word lengths and compute various statistics such as the median, mean, longest word, and most common word length.


```{r}
## Split the text into individual words
per_word_split <- strsplit(md, "\\W+")[[1]]

## Calculate the number of words in the text
number_of_words <- length(per_word_split)

## Calculate the length of each word
len_per_word <- nchar(per_word_split)

## Create a bar plot showing the distribution of word lengths
barplot(table(len_per_word), col = "dark blue", ylim = c(0, 60000), 
        main = "Number of Words per Length", xlab = "Word Length", ylab = "Frequency")
```


```{r}
## Calculate statistics on word lengths
median <- median(len_per_word, na.rm = TRUE)
mean <- mean(len_per_word, na.rm = TRUE)
longest <- max(len_per_word)
most_common <- names(sort(table(len_per_word), decreasing = TRUE)[1])

## Display the results
cat("\nThere are", number_of_words, "words in the text.\n")
cat("\nThe median length of words is:", median, "\n")
cat("The mean length of words is:", mean, "\n")
cat("The longest length of words is:", longest, "\n")
cat("The most common length of words is:", most_common, "\n")
```

### most frequent words:

Let's compute the frequency of each word in the text and display the top 10 most frequent words.

```{r}
## Calculate word frequencies
word_frequencies <- table(per_word_split)

## Display the top 10 most frequent words
top_words <- as.data.frame(sort(word_frequencies, decreasing = TRUE))[1:10,]
cat("\nTop 10 most frequent words in the text:\n")
print(top_words)
```


As we can see the top 10 most frequent words in the book are words like
"the" , "and" , "of" and so on .. this make sense and not a surprise
seeing how we use these words all the time to build sentences.




Below, we created a list of 137 chapters of the book, including
Etymology and Epilogue.

```{r}
chapters = strsplit(md, "\r\n    \r\n    \r\n      \r\n       \r\n    \r\n    \r\n      \r\n    \r\n      |\r\n\r\n      \r\n    \r\n      \r\n       \r\n    \r\n    \r\n      \r\n    \r\n      |\r\n     \r\n    \r\n      \r\n       \r\n    \r\n    \r\n      \r\n    \r\n      ")[[1]]
split_beginning = strsplit(chapters[1], "\r\n      \r\n      \r\n    \r\n      \r\n       \r\n      \r\n        \r\n      \r\n        ")[[1]]
split_ending = strsplit(chapters[137], "\r\n    \r\n\r\n")[[1]]
chapters[1] = split_beginning[2]
chapters[137] = split_ending[1]
```


Now, we used the chapters list we created above, and plotted the number
of words per chapter.

```{r}
num_of_words_vec = c()
chapter_index = seq(1:137)
for (chapter_j in chapters) {
  num_words_chapter_j = length(unlist(strsplit(chapter_j,"\\W+")))
  num_of_words_vec = c(num_of_words_vec,num_words_chapter_j)
}
ggplot(df_chapters_q2a, aes(x = chapter_index, y = num_of_words_vec)) +
  geom_bar(stat='identity', fill = "skyblue") +
  scale_x_continuous(breaks =  c(seq(1, 137, 7))) +
  ggtitle("Chapters vs Number of Words") +
  labs(x = "Chapter Index", y = "Number of Words") +
  theme_minimal()
```

We created a function that calculates a vector of relative frequencies
of a specific string in each chapter of the book.

```{r}
freq_func_q2 = function(word_q2, chapters_q2) {
  word_porportions_vec = c()
  for (chapter_i in chapters_q2) {
    true_in_i = str_count(chapter_i, as.character(word_q2))
    total_in_i = length(unlist(strsplit(chapter_i,"\\W+")))
    porportions_in_i = true_in_i / total_in_i
    word_porportions_vec = c(word_porportions_vec, porportions_in_i)
  }
  return(word_porportions_vec)
}
```

We calculated the relative frequencies of "Ahab", "Moby" and "sea"
strings, and plotted "Ahab" relative frequency.

```{r}
Ahab_q2_b = freq_func_q2("Ahab",chapters)
Moby_q2_b = freq_func_q2("Moby", chapters)
sea_q2_b = freq_func_q2("sea", chapters)
df_words_q2_b = data.frame(chapter_index, Ahab_q2_b, Moby_q2_b, sea_q2_b)

ggplot(df_words_q2_b, aes(x = chapter_index, y = Ahab_q2_b)) + geom_bar(stat='identity', fill = "skyblue") +scale_x_continuous(breaks =  c(seq(1,137,7))) + ggtitle("Porportions of 'Ahab' name apperance vs Chapters") +
  labs(x = "Chapter index", y = "Porportions of 'Ahab' appearnce in the chapter")
```



As above, we plotted "Moby" relative frequency.

```{r}
ggplot(df_words_q2_b, aes(x = chapter_index, y = Moby_q2_b)) + geom_bar(stat='identity', fill = "skyblue") +scale_x_continuous(breaks =  c(seq(1,137,7))) + ggtitle("Porportions of 'Moby' name apperance vs Chapters") +
  labs(x = "Chapter index", y = "Porportions of 'Moby' appearnce in the chapter")
```

"sea" relative frequencies is.

```{r}
ggplot(df_words_q2_b, aes(x = chapter_index, y = sea_q2_b)) + geom_bar(stat='identity', fill = "skyblue") +scale_x_continuous(breaks =  c(seq(1,137,7))) + ggtitle("Porportions of 'sea' apperance vs Chapters") +
  labs(x = "Chapter index", y = "Porportions of 'sea' appearnce in the chapter")
```

The plot shows how certain words are used in Moby Dick. "Sea" is used a lot from the start because the story mostly happens at sea. But words like "Ahab" and "Moby" show up less in the middle, then more towards the end. This means they become more important as the story goes on. It's like seeing the story unfold through the words that are used.



















